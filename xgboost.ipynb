{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Znerf/diabetes-detection/blob/main/code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqoTj2_vbCFp",
        "outputId": "464d8cde-3064-424e-9736-163b403044d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5idfJpTXX2Q",
        "outputId": "5a45f4e0-8eb8-4672-f83e-33ff50cba74f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oN9jcZSd-ul",
        "outputId": "31322f7e-c9d8-4237-813d-235d312e00de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting xgboost==1.7.5\n",
            "  Downloading xgboost-1.7.5-py3-none-manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost==1.7.5) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost==1.7.5) (1.13.1)\n",
            "Downloading xgboost-1.7.5-py3-none-manylinux2014_x86_64.whl (200.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.3/200.3 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xgboost\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 2.1.1\n",
            "    Uninstalling xgboost-2.1.1:\n",
            "      Successfully uninstalled xgboost-2.1.1\n",
            "Successfully installed xgboost-1.7.5\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost==1.7.5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Q5tXrHoAdOQ8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "IPYpkDX1dQ6a",
        "outputId": "4a718c02-4d19-4c79-8cb4-ecf9d4cebaa9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-6024d374-ea32-4fb9-b0e8-b6f8ef51b539\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Diabetes_binary</th>\n",
              "      <th>HighBP</th>\n",
              "      <th>HighChol</th>\n",
              "      <th>CholCheck</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Smoker</th>\n",
              "      <th>Stroke</th>\n",
              "      <th>HeartDiseaseorAttack</th>\n",
              "      <th>PhysActivity</th>\n",
              "      <th>Fruits</th>\n",
              "      <th>...</th>\n",
              "      <th>AnyHealthcare</th>\n",
              "      <th>NoDocbcCost</th>\n",
              "      <th>GenHlth</th>\n",
              "      <th>MentHlth</th>\n",
              "      <th>PhysHlth</th>\n",
              "      <th>DiffWalk</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>Education</th>\n",
              "      <th>Income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 22 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6024d374-ea32-4fb9-b0e8-b6f8ef51b539')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6024d374-ea32-4fb9-b0e8-b6f8ef51b539 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6024d374-ea32-4fb9-b0e8-b6f8ef51b539');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cc058c06-e517-42b0-a038-48574731aac1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cc058c06-e517-42b0-a038-48574731aac1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cc058c06-e517-42b0-a038-48574731aac1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
              "0              0.0     1.0       0.0        1.0  26.0     0.0     0.0   \n",
              "1              0.0     1.0       1.0        1.0  26.0     1.0     1.0   \n",
              "2              0.0     0.0       0.0        1.0  26.0     0.0     0.0   \n",
              "3              0.0     1.0       1.0        1.0  28.0     1.0     0.0   \n",
              "4              0.0     0.0       0.0        1.0  29.0     1.0     0.0   \n",
              "\n",
              "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
              "0                   0.0           1.0     0.0  ...            1.0   \n",
              "1                   0.0           0.0     1.0  ...            1.0   \n",
              "2                   0.0           1.0     1.0  ...            1.0   \n",
              "3                   0.0           1.0     1.0  ...            1.0   \n",
              "4                   0.0           1.0     1.0  ...            1.0   \n",
              "\n",
              "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
              "0          0.0      3.0       5.0      30.0       0.0  1.0   4.0        6.0   \n",
              "1          0.0      3.0       0.0       0.0       0.0  1.0  12.0        6.0   \n",
              "2          0.0      1.0       0.0      10.0       0.0  1.0  13.0        6.0   \n",
              "3          0.0      3.0       0.0       3.0       0.0  1.0  11.0        6.0   \n",
              "4          0.0      2.0       0.0       0.0       0.0  0.0   8.0        5.0   \n",
              "\n",
              "   Income  \n",
              "0     8.0  \n",
              "1     8.0  \n",
              "2     8.0  \n",
              "3     8.0  \n",
              "4     8.0  \n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Data/dataset_diabetes.csv')\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7Jiav-u_ddFF"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "jZMMJAMIMyvC"
      },
      "outputs": [],
      "source": [
        "y= df['Diabetes_binary']\n",
        "\n",
        "X=df.drop('Diabetes_binary',axis=1)\n",
        "# y.head()\n",
        "\n",
        "# X.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "zKIt2P8PNU2s"
      },
      "outputs": [],
      "source": [
        "# Create a StratifiedKFold object\n",
        "n_splits = 5  # Number of folds\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize a list to store the accuracy scores for each fold\n",
        "accuracy_scores = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWhG8woFMvxs",
        "outputId": "9b525eb1-a628-4c9e-98df-53f7567e74e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1: Accuracy = 0.7524577410000707\n",
            "Fold 2: Accuracy = 0.7523162882806422\n",
            "Fold 3: Accuracy = 0.7518036497382939\n",
            "Fold 4: Accuracy = 0.7514499929268638\n",
            "Fold 5: Accuracy = 0.7523695006365823\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Iterate through the folds\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Create DMatrix for XGBoost\n",
        "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "    # Set parameters for the XGBoost model\n",
        "    params = {\n",
        "      'objective': 'binary:logistic',\n",
        "      'eval_metric': 'logloss',\n",
        "      'eta': 0.1,\n",
        "      'max_depth': 3\n",
        "    }\n",
        "\n",
        "    # Train the model\n",
        "    model = xgb.train(params, dtrain, num_boost_round=100)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = model.predict(dtest)\n",
        "\n",
        "    # Evaluate the predictions and store the accuracy score\n",
        "    accuracy = accuracy_score(y_test, y_pred.round())\n",
        "    accuracy_scores.append(accuracy)\n",
        "\n",
        "    print(f\"Fold {fold + 1}: Accuracy = {accuracy}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7xLi9MSm85K",
        "outputId": "eba8ded8-ab4f-4617-8414-90c02854e821"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy: 0.7501839065445155\n"
          ]
        }
      ],
      "source": [
        "# Calculate the average accuracy across all folds\n",
        "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
        "print(f\"Average Accuracy: {average_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsRnDTbkPLbu",
        "outputId": "7e4a0127-d6d0-4b28-a35c-f12d39a22154"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1: XGBoost Accuracy = 0.7463045477049296, Random Forest Accuracy = 0.7394440908126458\n",
            "Fold 2: XGBoost Accuracy = 0.7482141594172148, Random Forest Accuracy = 0.7376759318197892\n",
            "Fold 3: XGBoost Accuracy = 0.7502475597680012, Random Forest Accuracy = 0.7380110340925167\n",
            "Fold 4: XGBoost Accuracy = 0.7468524543782713, Random Forest Accuracy = 0.7307257037770547\n",
            "Fold 5: XGBoost Accuracy = 0.7498231715942849, Random Forest Accuracy = 0.7390720045268072\n",
            "Average XGBoost Accuracy: 0.7482883785725404\n",
            "Average Random Forest Accuracy: 0.7369857530057626\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# ... (data loading and preprocessing) ...\n",
        "\n",
        "# Create a StratifiedKFold object\n",
        "n_splits = 5  # Number of folds\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store accuracy scores for each fold and each model\n",
        "xgb_accuracy_scores = []\n",
        "rf_accuracy_scores = []\n",
        "\n",
        "# Iterate through the folds\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # XGBoost model training and evaluation\n",
        "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "    params = {\n",
        "        # ... (your XGBoost parameters) ...\n",
        "    }\n",
        "    xgb_model = xgb.train(params, dtrain, num_boost_round=100)\n",
        "    xgb_y_pred = xgb_model.predict(dtest)\n",
        "    xgb_accuracy = accuracy_score(y_test, xgb_y_pred.round())\n",
        "    xgb_accuracy_scores.append(xgb_accuracy)\n",
        "\n",
        "    # Random Forest model training and evaluation\n",
        "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)  # Adjust parameters as needed\n",
        "    rf_model.fit(X_train, y_train)\n",
        "    rf_y_pred = rf_model.predict(X_test)\n",
        "    rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
        "    rf_accuracy_scores.append(rf_accuracy)\n",
        "\n",
        "    print(f\"Fold {fold + 1}: XGBoost Accuracy = {xgb_accuracy}, Random Forest Accuracy = {rf_accuracy}\")\n",
        "\n",
        "# Calculate average accuracy for each model\n",
        "average_xgb_accuracy = sum(xgb_accuracy_scores) / len(xgb_accuracy_scores)\n",
        "average_rf_accuracy = sum(rf_accuracy_scores) / len(rf_accuracy_scores)\n",
        "\n",
        "print(f\"Average XGBoost Accuracy: {average_xgb_accuracy}\")\n",
        "print(f\"Average Random Forest Accuracy: {average_rf_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEwgxLqvQHKr",
        "outputId": "8404754e-c622-46eb-f95c-6789ddc0d284"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 28277, number of negative: 28276\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016168 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 198\n",
            "[LightGBM] [Info] Number of data points in the train set: 56553, number of used features: 21\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500009 -> initscore=0.000035\n",
            "[LightGBM] [Info] Start training from score 0.000035\n",
            "Fold 1: XGBoost Accuracy = 0.7498231715942849, Random Forest Accuracy = 0.7390720045268072, LightGBM Accuracy = 0.7513261192446424\n",
            "[LightGBM] [Info] Number of positive: 28276, number of negative: 28277\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011228 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 197\n",
            "[LightGBM] [Info] Number of data points in the train set: 56553, number of used features: 21\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499991 -> initscore=-0.000035\n",
            "[LightGBM] [Info] Start training from score -0.000035\n",
            "Fold 2: XGBoost Accuracy = 0.7498231715942849, Random Forest Accuracy = 0.7390720045268072, LightGBM Accuracy = 0.7524577410000707\n",
            "[LightGBM] [Info] Number of positive: 28277, number of negative: 28277\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011521 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 199\n",
            "[LightGBM] [Info] Number of data points in the train set: 56554, number of used features: 21\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "Fold 3: XGBoost Accuracy = 0.7498231715942849, Random Forest Accuracy = 0.7390720045268072, LightGBM Accuracy = 0.75187438110058\n",
            "[LightGBM] [Info] Number of positive: 28277, number of negative: 28277\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011219 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 198\n",
            "[LightGBM] [Info] Number of data points in the train set: 56554, number of used features: 21\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "Fold 4: XGBoost Accuracy = 0.7498231715942849, Random Forest Accuracy = 0.7390720045268072, LightGBM Accuracy = 0.7518036497382939\n",
            "[LightGBM] [Info] Number of positive: 28277, number of negative: 28277\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011213 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 199\n",
            "[LightGBM] [Info] Number of data points in the train set: 56554, number of used features: 21\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "Fold 5: XGBoost Accuracy = 0.7498231715942849, Random Forest Accuracy = 0.7390720045268072, LightGBM Accuracy = 0.7548450983165936\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import lightgbm as lgb\n",
        "\n",
        "# ... (data loading and preprocessing) ...\n",
        "\n",
        "# Create a StratifiedKFold object\n",
        "n_splits = 5  # Number of folds\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store accuracy scores for each fold and each model\n",
        "xgb_accuracy_scores = []\n",
        "rf_accuracy_scores = []\n",
        "lgb_accuracy_scores = []\n",
        "\n",
        "# Iterate through the folds\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # XGBoost model training and evaluation\n",
        "    # ... (XGBoost code as before) ...\n",
        "\n",
        "    # Random Forest model training and evaluation\n",
        "    # ... (Random Forest code as before) ...\n",
        "\n",
        "    # LightGBM model training and evaluation\n",
        "    lgb_train = lgb.Dataset(X_train, label=y_train)\n",
        "    lgb_test = lgb.Dataset(X_test, label=y_test, reference=lgb_train)\n",
        "    params = {\n",
        "        'objective': 'binary',  # Adjust objective as needed\n",
        "        'metric': 'binary_logloss',  # Adjust metric as needed\n",
        "        # ... (other LightGBM parameters) ...\n",
        "    }\n",
        "    lgb_model = lgb.train(params, lgb_train, valid_sets=[lgb_train, lgb_test], num_boost_round=100)\n",
        "    lgb_y_pred = lgb_model.predict(X_test, num_iteration=lgb_model.best_iteration)\n",
        "    lgb_accuracy = accuracy_score(y_test, (lgb_y_pred > 0.5).astype(int))  # Assuming binary classification\n",
        "    lgb_accuracy_scores.append(lgb_accuracy)\n",
        "\n",
        "    print(f\"Fold {fold + 1}: XGBoost Accuracy = {xgb_accuracy}, Random Forest Accuracy = {rf_accuracy}, LightGBM Accuracy = {lgb_accuracy}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQ6PL1FJQcLk",
        "outputId": "c7810843-4fdb-4a0b-c3ca-5c8ad1a32dec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average LightGBM Accuracy: 0.7524613978800361\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Calculate average accuracy for each model\n",
        "# average_xgb_accuracy = sum(xgb_accuracy_scores) / len(xgb_accuracy_scores)\n",
        "# average_rf_accuracy = sum(rf_accuracy_scores) / len(rf_accuracy_scores)\n",
        "average_lgb_accuracy = sum(lgb_accuracy_scores) / len(lgb_accuracy_scores)\n",
        "\n",
        "# print(f\"Average XGBoost Accuracy: {average_xgb_accuracy}\")\n",
        "# print(f\"Average Random Forest Accuracy: {average_rf_accuracy}\")\n",
        "print(f\"Average LightGBM Accuracy: {average_lgb_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoAhB6k0Q-V1",
        "outputId": "79dfb0c3-d1e5-4e28-eb58-157c35dbfbba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1: XGBoost Accuracy = 0.7498231715942849, Random Forest Accuracy = 0.7390720045268072, LightGBM Accuracy = 0.7548450983165936, SVM Accuracy = 0.7515382983237853\n",
            "Fold 2: XGBoost Accuracy = 0.7498231715942849, Random Forest Accuracy = 0.7390720045268072, LightGBM Accuracy = 0.7548450983165936, SVM Accuracy = 0.7479312539783577\n",
            "Fold 3: XGBoost Accuracy = 0.7498231715942849, Random Forest Accuracy = 0.7390720045268072, LightGBM Accuracy = 0.7548450983165936, SVM Accuracy = 0.7469939171028434\n",
            "Fold 4: XGBoost Accuracy = 0.7498231715942849, Random Forest Accuracy = 0.7390720045268072, LightGBM Accuracy = 0.7548450983165936, SVM Accuracy = 0.7449427075965483\n",
            "Fold 5: XGBoost Accuracy = 0.7498231715942849, Random Forest Accuracy = 0.7390720045268072, LightGBM Accuracy = 0.7548450983165936, SVM Accuracy = 0.749893902956571\n",
            "Average SVM Accuracy: 0.7482600159916212\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import lightgbm as lgb\n",
        "from sklearn.svm import SVC  # Import SVC\n",
        "\n",
        "# ... (data loading and preprocessing) ...\n",
        "\n",
        "# Create a StratifiedKFold object\n",
        "n_splits = 5  # Number of folds\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store accuracy scores for each fold and each model\n",
        "xgb_accuracy_scores = []\n",
        "rf_accuracy_scores = []\n",
        "lgb_accuracy_scores = []\n",
        "svm_accuracy_scores = []  # List for SVM accuracy scores\n",
        "\n",
        "# Iterate through the folds\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # XGBoost model training and evaluation\n",
        "    # ... (XGBoost code as before) ...\n",
        "\n",
        "    # Random Forest model training and evaluation\n",
        "    # ... (Random Forest code as before) ...\n",
        "\n",
        "    # LightGBM model training and evaluation\n",
        "    # ... (LightGBM code as before) ...\n",
        "\n",
        "    # SVM model training and evaluation\n",
        "    svm_model = SVC(kernel='linear', random_state=42)  # Adjust kernel and other parameters as needed\n",
        "    svm_model.fit(X_train, y_train)\n",
        "    svm_y_pred = svm_model.predict(X_test)\n",
        "    svm_accuracy = accuracy_score(y_test, svm_y_pred)\n",
        "    svm_accuracy_scores.append(svm_accuracy)  # Append SVM accuracy to the list\n",
        "\n",
        "    print(f\"Fold {fold + 1}: XGBoost Accuracy = {xgb_accuracy}, Random Forest Accuracy = {rf_accuracy}, LightGBM Accuracy = {lgb_accuracy}, SVM Accuracy = {svm_accuracy}\")\n",
        "\n",
        "# Calculate average accuracy for each model\n",
        "# ... (average accuracy calculations for XGBoost, Random Forest, LightGBM as before) ...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCI99fF8gNI8",
        "outputId": "6d24643c-4976-4e9c-b672-da891f819799"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average SVM Accuracy: 0.7482600159916212\n"
          ]
        }
      ],
      "source": [
        "average_svm_accuracy = sum(svm_accuracy_scores) / len(svm_accuracy_scores)  # Calculate average SVM accuracy\n",
        "print(f\"Average SVM Accuracy: {average_svm_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAmxi1weg9sn",
        "outputId": "3d15d852-2d18-44ad-fc30-8b9b0554a943"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
            "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 28277, number of negative: 28276\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015590 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 198\n",
            "[LightGBM] [Info] Number of data points in the train set: 56553, number of used features: 21\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500009 -> initscore=0.000035\n",
            "[LightGBM] [Info] Start training from score 0.000035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
            "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 28276, number of negative: 28277\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012109 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 197\n",
            "[LightGBM] [Info] Number of data points in the train set: 56553, number of used features: 21\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499991 -> initscore=-0.000035\n",
            "[LightGBM] [Info] Start training from score -0.000035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
            "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 28277, number of negative: 28277\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011850 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 199\n",
            "[LightGBM] [Info] Number of data points in the train set: 56554, number of used features: 21\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
            "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 28277, number of negative: 28277\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012275 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 198\n",
            "[LightGBM] [Info] Number of data points in the train set: 56554, number of used features: 21\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import numpy as np\n",
        "\n",
        "# Initialize the meta-model (Logistic Regression in this case)\n",
        "meta_model = LogisticRegression()\n",
        "\n",
        "# Create StratifiedKFold\n",
        "n_splits = 5\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store accuracy scores and predictions\n",
        "xgb_accuracy_scores = []\n",
        "rf_accuracy_scores = []\n",
        "lgb_accuracy_scores = []\n",
        "svm_accuracy_scores = []\n",
        "meta_accuracy_scores = []\n",
        "\n",
        "# Meta-model training data\n",
        "meta_train = np.zeros((len(X), 4))  # 4 because we have 4 models\n",
        "meta_test = np.zeros((len(X_test), 4))\n",
        "\n",
        "# Iterate through the folds\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # SVM model\n",
        "    svm_model = SVC(probability=True)\n",
        "    svm_model.fit(X_train, y_train)\n",
        "    svm_y_pred = svm_model.predict(X_test)\n",
        "    svm_accuracy = accuracy_score(y_test, svm_y_pred)\n",
        "    svm_accuracy_scores.append(svm_accuracy)\n",
        "\n",
        "    # XGBoost model\n",
        "    xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "    xgb_model.fit(X_train, y_train)\n",
        "    xgb_y_pred = xgb_model.predict(X_test)\n",
        "    xgb_accuracy = accuracy_score(y_test, xgb_y_pred)\n",
        "    xgb_accuracy_scores.append(xgb_accuracy)\n",
        "\n",
        "    # Random Forest model\n",
        "    rf_model = RandomForestClassifier(n_estimators=100)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "    rf_y_pred = rf_model.predict(X_test)\n",
        "    rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
        "    rf_accuracy_scores.append(rf_accuracy)\n",
        "\n",
        "    # LightGBM model\n",
        "    lgb_train = lgb.Dataset(X_train, label=y_train)\n",
        "    lgb_model = lgb.train(\n",
        "        {'objective': 'binary', 'metric': 'binary_logloss'},\n",
        "        lgb_train,\n",
        "        num_boost_round=100\n",
        "    )\n",
        "    lgb_y_pred = (lgb_model.predict(X_test) > 0.5).astype(int)\n",
        "    lgb_accuracy = accuracy_score(y_test, lgb_y_pred)\n",
        "    lgb_accuracy_scores.append(lgb_accuracy)\n",
        "\n",
        "    # Collect predictions for meta-model\n",
        "    meta_train[test_index, 0] = svm_model.predict_proba(X_test)[:, 1]  # SVM probabilities\n",
        "    meta_train[test_index, 1] = xgb_model.predict_proba(X_test)[:, 1]  # XGBoost probabilities\n",
        "    meta_train[test_index, 2] = rf_model.predict_proba(X_test)[:, 1]   # Random Forest probabilities\n",
        "    meta_train[test_index, 3] = lgb_model.predict(X_test)              # LightGBM probabilities\n",
        "\n",
        "# Train meta-model (Logistic Regression) on the stacked predictions\n",
        "meta_model.fit(meta_train, y)\n",
        "\n",
        "# Meta-model evaluation on test data\n",
        "meta_test[:, 0] = svm_model.predict_proba(X_test)[:, 1]\n",
        "meta_test[:, 1] = xgb_model.predict_proba(X_test)[:, 1]\n",
        "meta_test[:, 2] = rf_model.predict_proba(X_test)[:, 1]\n",
        "meta_test[:, 3] = lgb_model.predict(X_test)\n",
        "\n",
        "meta_y_pred = meta_model.predict(meta_test)\n",
        "meta_accuracy = accuracy_score(y_test, meta_y_pred)\n",
        "meta_accuracy_scores.append(meta_accuracy)\n",
        "\n",
        "print(f\"Meta-model accuracy: {meta_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "pfpB6IPPBDky",
        "outputId": "2f68fd69-2183-4379-e50c-22952930dc70"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'meta_model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b97a9f23059e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train meta-model (Logistic Regression) on the stacked predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmeta_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Meta-model evaluation on test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmeta_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'meta_model' is not defined"
          ]
        }
      ],
      "source": [
        "# Train meta-model (Logistic Regression) on the stacked predictions\n",
        "meta_model.fit(meta_train, y)\n",
        "\n",
        "# Meta-model evaluation on test data\n",
        "meta_test[:, 0] = svm_model.predict_proba(X_test)[:, 1]\n",
        "meta_test[:, 1] = xgb_model.predict_proba(X_test)[:, 1]\n",
        "meta_test[:, 2] = rf_model.predict_proba(X_test)[:, 1]\n",
        "meta_test[:, 3] = lgb_model.predict(X_test)\n",
        "\n",
        "meta_y_pred = meta_model.predict(meta_test)\n",
        "meta_accuracy = accuracy_score(y_test, meta_y_pred)\n",
        "meta_accuracy_scores.append(meta_accuracy)\n",
        "\n",
        "print(f\"Meta-model accuracy: {meta_accuracy}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
